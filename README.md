# Spatial Audio-Augmented Computer Vision: An Approach to Spatial Audio Cues Using the Apple Vision Pro

A research project exploring how spatial audio cues on Apple Vision Pro can enhance object recognition and navigation for visually impaired users.

## Research Question

How do computer vision-driven spatial audio cues using the Apple Vision Pro affect real-world object recognition accuracy and response time for visually impaired users?

## Primary Objectives

1. Develop effective spatial audio cues for common indoor objects
2. Achieve 85% accuracy for object identification
3. Reduce navigation time by 30%
4. Validate the effectiveness vs real-world identification

## Features

- Real-time object detection using ARKit and RealityKit
- Spatial audio cue system for directional object information
- Navigation assistance with audio feedback
- Data collection and analysis tools for user studies

## Technology Stack

- **Platform**: visionOS (Apple Vision Pro)
- **Frameworks**: ARKit, RealityKit, SwiftUI
- **Language**: Swift
- **Audio**: Spatial Audio APIs

## Documentation

- [Technical Documentation](DOCUMENTATION.md) — Architecture, components, and implementation details
- [Research Protocol](Documentation/ResearchProtocol.md) — Study design and research objectives
- [Technical Specifications](Documentation/TechnicalSpecs.md) — Detailed system specs
- [Update Log](Documentation/UpdateLog.md) — Changelog and revision history

## AI Usage Disclosure

This project utilized AI assistance for development support and code review. Specifically:
- **Code review and debugging**: AI helped identify potential issues and suggest improvements in Swift/visionOS implementation
- **Development assistance**: AI provided guidance on ARKit/RealityKit best practices and spatial audio implementation patterns

## Contact

**Developer:** Amelia Eckard
**Email:** aeckard3@charlotte.edu
**Research Advisor:** Todd Dobbs
**Institution:** University of North Carolina at Charlotte
